{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0DhP-ME8mCL",
    "outputId": "d46b097e-7fa5-4272-859f-03da80e270f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0T-oKFYBMWDc",
    "outputId": "f404ffc4-92e2-4a15-ca77-947889a12e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting POT\n",
      "  Downloading POT-0.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from POT) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from POT) (1.13.1)\n",
      "Downloading POT-0.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (835 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/835.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m835.4/835.4 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: POT\n",
      "Successfully installed POT-0.9.4\n"
     ]
    }
   ],
   "source": [
    "pip install POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfJ8yTpWu0DR",
    "outputId": "69f6c72d-f222-47a9-f2e4-6a0cd5f9ca89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIRJa1OMH89L"
   },
   "outputs": [],
   "source": [
    "question_1 = [\"What is virtual memory?\",\n",
    "            \"What is a kernel?\",\n",
    "            \"What is a Thread?\",\n",
    "            \"What is Buffer?\",\n",
    "            \"What is demand paging?\",\n",
    "            \"what are functions of operating system?\",\n",
    "            \"Explain the difference between preemptive and non-preemptive scheduling.\",\n",
    "            \"Describe the role of the kernel in an operating system.\",\n",
    "            \"What is deadlock in operating systems, and how can it be prevented?\",\n",
    "            \"Explain the concept of context switching in an operating system.\"\n",
    "           ]\n",
    "correct_answer1_1 = [\"Virtual memory creates an illusion that each user has one or more contiguous address spaces, each beginning at address zero. The sizes of such virtual address spaces are generally very high. The idea of virtual memory is to use disk space to extend the RAM. Running processes don’t need to care whether the memory is from RAM or disk. The illusion of such a large amount of memory is created by subdividing the virtual memory into smaller pieces, which can be loaded into physical memory whenever they are needed by a process.\",\n",
    "                   \"A kernel is the central component of an operating system that manages the operations of computers and hardware. It basically manages operations of memory and CPU time. It is a core component of an operating system. Kernel acts as a bridge between applications and data processing performed at the hardware level using inter-process communication and system calls.\",\n",
    "                   \"A thread is like a mini program within a program (process) in your operating system. It's a single path of execution that allows a process to do multiple things at once. Imagine a web browser - you can have multiple tabs open (threads) while still using the browser itself (process). Threads share resources with each other, making them lightweight and faster to create than separate processes.\",\n",
    "                   \"A buffer is a memory area that stores data being transferred between two devices or between a device and an application. This mechanism is crucial for managing data that is being moved between different processes or between hardware devices and software processes.\",\n",
    "                   \"The process of loading the page into memory on demand (whenever a page fault occurs) is known as demand paging. it is a virtual memory technique\",\n",
    "                   \"The main functions of an operating system (OS) include managing the computer's hardware resources, such as the CPU, memory, and input/output devices. The OS acts as an intermediary between the user and the hardware, ensuring that software applications can effectively utilize the hardware. Additionally, the OS provides a user interface, which can be graphical (GUI) or command-line (CLI), facilitating user interaction with the system. It also handles process management, which includes scheduling processes, ensuring efficient execution, and managing multitasking. Memory management is another critical function, involving the allocation and deallocation of memory space as needed by various programs. Furthermore, the OS ensures file system management, organizing data into files and directories, and managing access to these files.\",\n",
    "                   \"Preemptive scheduling is a process management technique used by operating systems where the scheduler can interrupt and suspend a currently running process to allocate the CPU to another process. This is particularly useful in ensuring that high-priority processes receive adequate CPU time and that the system remains responsive, especially in a multitasking environment. Preemptive scheduling allows for better utilization of CPU resources and improved system performance by dynamically adjusting to the varying demands of different processes. Common algorithms that use preemptive scheduling include Round Robin, Shortest Remaining Time First (SRTF), and Priority Scheduling. By contrast, non-preemptive scheduling allows a running process to continue until it either completes its execution or voluntarily yields control of the CPU. Non-preemptive scheduling is simpler to implement and incurs less overhead since context switches are minimized, but it can lead to issues like the convoy effect, where short processes are delayed by longer ones.\",\n",
    "                   \"The kernel is the core component of an operating system, acting as a bridge between the hardware and software layers. It manages the system's resources, including the CPU, memory, and peripheral devices, ensuring efficient and secure operation. The kernel handles process management, enabling multitasking by allowing multiple processes to share the CPU while maintaining isolation between them. It also manages memory allocation, ensuring that each process has adequate memory space and that no two processes interfere with each other. Additionally, the kernel oversees hardware communication through device drivers, translating software instructions into hardware actions. Security and access control are also critical functions of the kernel, which enforces permissions and protects against unauthorized access. By performing these essential tasks, the kernel ensures system stability and performance.\",\n",
    "                   \"Deadlock in operating systems occurs when a set of processes become permanently blocked, waiting for each other to release resources they need to proceed. This situation typically involves four conditions: mutual exclusion, hold and wait, no preemption, and circular wait. To prevent deadlock, operating systems can implement strategies such as deadlock avoidance, deadlock prevention, and deadlock detection and recovery. Deadlock avoidance involves dynamically examining resource allocation to ensure that a circular wait condition never occurs, often using algorithms like Banker's algorithm. Deadlock prevention aims to break one of the necessary conditions for deadlock by imposing restrictions, such as requiring processes to request all resources upfront or only allowing resource holding without wait. Deadlock detection involves monitoring system state and resource allocation to identify deadlocks and recover from them by terminating or rolling back processes. These strategies help maintain system stability and resource availability.\",\n",
    "                   \"Context switching in an operating system is the process of saving the state of a currently running process so that another process can be executed. This involves storing the current context (registers, program counter, and other process-specific data) of the running process and loading the context of the next process to be executed. Context switching is essential for multitasking, allowing the operating system to efficiently manage multiple processes by rapidly switching between them, giving the illusion of parallel execution. Although necessary for multitasking, context switching is computationally expensive because it involves saving and loading process states, which can impact system performance. Efficient context switching mechanisms are crucial for maintaining the balance between responsiveness and performance in multitasking environments.\"\n",
    "                  ]\n",
    "\n",
    "correct_answer2_1 = [\"Virtual memory is a storage allocation technique in a computer's operating system (OS) that uses secondary storage, like a hard disk, to temporarily store data when a computer runs out of random access memory (RAM). This technique frees up RAM space and makes it seem like the computer has more main memory.\",\n",
    "                   \"The kernel is the core component of an operating system that manages system resources, such as memory, CPU, and input/output devices. It acts as a bridge between software and hardware, handling tasks like process scheduling, memory management, and device communication.\",\n",
    "                   \"Thread is the smallest unit of execution within a process. Threads share the same memory space and resources of their parent process, allowing for concurrent execution of tasks within a single program. Threads enable parallelism, multitasking, and responsiveness in applications by allowing multiple operations to be performed simultaneously.\",\n",
    "                   \"a buffer is a temporary holding area, typically located in the computer's RAM (Random Access Memory). Its purpose is to act as a staging ground for data that's being transferred between different parts of the system or between the system and external devices.\",\n",
    "                   \"Demand paging is a virtual memory technique where the operating system loads only the sections (pages) of a program into main memory that are currently needed, improving memory utilization.\",\n",
    "                   \"An operating system's primary functions include resource management, user interface provision, and system security. Resource management involves the efficient allocation of the computer’s CPU, memory, and peripheral devices to various applications. This ensures optimal performance and prevents resource conflicts. The OS also provides a user interface, allowing users to interact with the system through commands or graphical elements. Security management is another crucial function, where the OS protects system data from unauthorized access and ensures data integrity. This includes implementing access controls, authentication mechanisms, and maintaining system logs. Additionally, the OS oversees task scheduling, process coordination, and memory management, ensuring smooth and efficient execution of programs.\",\n",
    "                   \"Preemptive scheduling is a CPU scheduling method where the operating system can forcibly remove a running process from the CPU to allocate resources to another process, typically one with a higher priority. This method is essential in real-time and interactive systems where responsiveness is critical. Preemptive scheduling ensures that high-priority tasks receive timely CPU access, improving overall system responsiveness and efficiency. Examples include the Round Robin and Priority Scheduling algorithms, which allow the system to handle high-priority tasks promptly. Conversely, non-preemptive scheduling means that once a process starts executing, it runs to completion or until it voluntarily releases the CPU. This approach simplifies process management and reduces overhead, as fewer context switches are required. However, it can lead to inefficiencies, particularly in systems where short tasks must wait for longer tasks to complete, potentially degrading system performance.\",\n",
    "                   \"The kernel is the central part of an operating system responsible for managing hardware resources and providing essential services to other software components. It operates in a privileged mode, with unrestricted access to all hardware and system resources. The kernel's primary functions include process management, memory management, and device management. Process management involves scheduling and executing processes, ensuring efficient CPU utilization and isolation between processes. Memory management includes allocating and deallocating memory as needed, handling virtual memory, and maintaining memory protection. Device management involves interfacing with hardware devices through device drivers, allowing the OS to communicate with peripherals such as hard drives, printers, and network cards. The kernel also handles system calls, which are requests from applications for services like file operations, input/output processing, and inter-process communication. By managing these critical functions, the kernel ensures the system runs smoothly, securely, and efficiently.\",\n",
    "                   \"Deadlock is a situation in operating systems where a set of processes are unable to proceed because each process is waiting for a resource that another process holds. This results in a cycle of dependencies with no process able to complete. Preventing deadlock can be achieved through various methods. One approach is deadlock prevention, which modifies system conditions to make deadlocks impossible by negating one of the four Coffman conditions: mutual exclusion, hold and wait, no preemption, and circular wait. For example, the hold and wait condition can be prevented by requiring processes to request all resources at once. Another approach is deadlock avoidance, which dynamically checks resource-allocation states to ensure that a circular wait cannot occur, typically implemented using the Banker's algorithm. Deadlock detection involves allowing deadlocks to occur but having mechanisms to detect and resolve them, such as by forcibly reclaiming resources from certain processes. By implementing these strategies, operating systems can effectively manage resources and ensure smooth process execution.\",\n",
    "                   \"Context switching is a crucial mechanism in operating systems that enables multitasking by allowing the CPU to switch between different processes. When a context switch occurs, the operating system saves the state of the currently running process, including the values of registers, program counter, and other essential information, into a data structure known as the process control block (PCB). It then loads the state of the next process to be executed from its PCB, effectively switching the CPU's attention from one process to another. This process ensures that multiple processes can share the CPU without interfering with each other, providing the user with a seamless multitasking experience. However, context switching has an overhead due to the time taken to save and load process states, which can affect overall system performance if not managed efficiently.\"\n",
    "                  ]\n",
    "\n",
    "wrong_answer1_1 = [\"Virtual memory is a type of online storage system accessed through the cloud, similar to Google Drive or Dropbox.  It allows you to store files remotely and access them from any device.  While virtual memory can be used to free up space on your computer's hard drive.\",\n",
    "                 \"The kernel is a fancy word for the recycling bin in your operating system. Whenever you delete a file or program, it doesn't actually disappear. Instead, the kernel throws it into the kernel, a temporary storage space. This allows you to easily recover accidentally deleted files.\",\n",
    "                 \"Thread is a fancy term for a shortcut on your desktop. Clicking a thread icon quickly opens a specific part of a program, kind of like having multiple bookmarks within one app.\",\n",
    "                 \"A buffer in a special type of program that automatically compresses data. This compressed data takes up less space, allowing more information to be squeezed into the buffer.\",\n",
    "                 \"Demand paging is a method where the operating system pre-loads all program data into RAM for faster access, even if it's not immediately required.\",\n",
    "                 \"The primary function of an operating system is to provide internet connectivity to the computer. Without an OS, a computer would not be able to connect to the internet or run any web-based applications. Another critical function is to manage and control the RGB lighting of the computer’s hardware. The OS ensures that the lighting patterns are synchronized and customizable according to the user's preferences. Furthermore, the OS is responsible for maintaining the computer’s battery life, adjusting power settings to optimize performance. Lastly, it handles all software updates, ensuring that applications are automatically updated without user intervention.\",\n",
    "                 \"Preemptive scheduling is exclusively used in single-task operating systems where only one task can run at a time. The OS uses preemptive scheduling to ensure that the single task gets uninterrupted CPU time, making the system efficient for real-time applications. In contrast, non-preemptive scheduling is designed for multi-tasking operating systems where multiple processes share CPU time. The OS allows processes to run until they complete or voluntarily yield control, thus facilitating an efficient multi-tasking environment. This is incorrect because preemptive scheduling is actually a hallmark of multi-tasking systems, enabling the OS to switch tasks to ensure fair CPU allocation, while non-preemptive scheduling is less common in modern multi-tasking environments due to its inefficiency in handling high-priority tasks promptly.\",\n",
    "                 \"The kernel is a part of the operating system that primarily handles user interactions and customizations. It manages the user interface, allowing users to customize themes, wallpapers, and desktop layouts. Additionally, the kernel is responsible for managing the audio-visual aspects of the system, ensuring high-quality sound and video output. It also handles user account management, including setting up passwords and user profiles. The kernel's main job is to enhance the user experience by providing customizable options and ensuring smooth multimedia performance. This focus on user interaction and customization makes the kernel a crucial part of the operating system for delivering a personalized user experience.\",\n",
    "                 \"A deadlock in operating systems refers to a situation where multiple processes are able to run without needing any resources from each other, allowing them to complete their tasks independently. This state is highly desirable as it maximizes system efficiency and resource utilization. Deadlocks are prevented by ensuring that all processes always have immediate access to any resources they request. This can be achieved by duplicating all critical resources so that no process ever has to wait, thus eliminating any potential for conflicts. Additionally, implementing a first-come, first-served policy for resource allocation ensures that processes are handled in a fair and orderly manner, further reducing the risk of deadlock. Regularly restarting the system also helps to clear any potential deadlock conditions. By combining these strategies, operating systems can effectively prevent deadlocks and ensure smooth and uninterrupted operation.\",\n",
    "                 \"Context switching refers to the process of switching between different user interfaces on the operating system, such as switching from a desktop environment to a command-line interface. This involves saving the current state of the user interface, including open windows, application states, and user preferences, and then loading the new interface state. The primary purpose of context switching is to provide users with flexibility in choosing their preferred working environment. This process does not involve any changes in the running processes or CPU scheduling and is solely focused on user interface management. Effective context switching ensures a smooth transition between different interfaces without losing user data\"\n",
    "                ]\n",
    "\n",
    "wrong_answer2_1 = [\"Virtual memory speeds upour y computer by automatically deleting unused files.  Virtual memory itself doesn't delete files. It  swaps less used data between RAM and the hard drive, making space for active programs. While this can improve performance in some situations, it's not directly deleting files\",\n",
    "                 \"The kernel acts like a powerful app store for your computer. Different programs you install (like games, web browsers) are individual kernels that the operating system can load and run depending on your needs. This allows for a more modular system and easier updates for specific functionalities.\",\n",
    "                 \"Threads in an operating system are like tiny superhighways inside your computer. These invisible cables come in different colors to represent different tasks. Data packets whiz through these threads at incredible speeds, carrying information between the CPU, RAM, and other hardware components. The operating system acts like a traffic controller, making sure the data doesn't get jammed and everything runs smoothly.\",\n",
    "                 \"A buffer is a program that automatically corrects errors in data before it's transferred. It scans the data for any mistakes and fixes them on the fly. This ensures that only perfect data reaches its destination.\",\n",
    "                 \"Demand paging is a fancy term for when your computer runs out of physical memory and has to restart programs from scratch.\",\n",
    "                 \"An operating system's main function is to enhance the graphical quality of the computer's display. It works primarily to improve the resolution and color accuracy of the screen. Another significant function is to provide entertainment by running games and multimedia applications. The OS is also primarily responsible for managing the sound system, ensuring high-quality audio output. Additionally, it takes care of social media integration, allowing users to access and manage their social media accounts directly from the desktop. These functions ensure that the user has an enjoyable and visually appealing experience while using the computer.\",\n",
    "                 \"In preemptive scheduling, the operating system depends heavily on user input to determine when to switch between processes. When a user interacts with the system, such as clicking a mouse or typing on the keyboard, the OS takes this as a signal to preempt the current process and switch to another. This ensures that user interactions always receive immediate attention. Conversely, non-preemptive scheduling relies solely on the system timer to manage process switching. The OS checks the system clock and, at fixed intervals, forcibly switches processes based on a predetermined schedule. This explanation is incorrect because preemptive scheduling is typically managed by the system timer and other internal mechanisms to ensure responsive multitasking, whereas non-preemptive scheduling allows a process to run until it voluntarily releases control of the CPU, without relying on user input or timed intervals.\",\n",
    "                 \"The kernel in an operating system is primarily responsible for networking functions, including managing internet connections and data transfers between devices. It ensures that the system can connect to various networks, maintain stable connections, and manage data traffic efficiently. The kernel also plays a key role in enhancing the system's graphical capabilities, providing support for high-resolution displays and advanced graphical effects. Additionally, it handles the installation and updating of software applications, ensuring that all installed programs are up-to-date and compatible with the system. These networking and graphical management responsibilities make the kernel essential for maintaining an interconnected and visually appealing operating system.\",\n",
    "                 \"Deadlock in operating systems occurs when multiple processes are able to share resources freely without any restrictions, leading to optimal performance and resource usage. In such scenarios, processes can simultaneously access and modify resources, which results in faster execution and increased efficiency. Deadlocks can be prevented by allowing processes to preempt each other's resources at any time, ensuring that no process has to wait. This approach is implemented by enabling processes to forcibly take control of the resources they need, regardless of the state of other processes. Additionally, increasing the system's resource pool to an infinite amount guarantees that all processes can always acquire the resources they need, completely eliminating the possibility of deadlock. By adopting these measures, an operating system can effectively manage resources and avoid any potential deadlock situations.\",\n",
    "                 \"Context switching is the mechanism by which an operating system changes the network connection from one protocol to another, such as switching from Wi-Fi to Ethernet. This involves saving the state of the current network connection, including active sessions, IP addresses, and port configurations, and then establishing the new connection with the required settings. Context switching is crucial for maintaining network connectivity, especially in environments where network conditions frequently change. This process ensures that applications and services continue to operate seamlessly during network transitions. However, context switching between network protocols can be resource-intensive and may introduce latency, affecting the performance of network-dependent applications.\"\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSxOAcyMjwr-"
   },
   "outputs": [],
   "source": [
    "question_2 = [\"What is the OSI model, and why is it important in networking?\",\n",
    "            \"What is the difference between TCP and UDP?\",\n",
    "            \"What is network latency, and how does it affect performance?\",\n",
    "            \"What is DNS, and how does it function in a network?\",\n",
    "            \"What is bandwidth, and why is it important in networking?\",\n",
    "            \"What is NAT, and how does it improve security in a network?\",\n",
    "            \"What is VPN, and how does it work?\",\n",
    "            \"What is IP addressing, and why is it important?\",\n",
    "            \"What is a firewall, and how does it protect a network?\",\n",
    "            \"What is a subnet, and why is subnetting important in networks?\"\n",
    "           ]\n",
    "correct_answer1_2 = [\"The OSI (Open Systems Interconnection) model is a conceptual framework that standardizes the functions of a telecommunication or computing system without regard to its underlying internal structure and technology. It divides network communication into seven layers: Physical, Data Link, Network, Transport, Session, Presentation, and Application. This model is important because it provides a universal language and standards for network systems to communicate, making interoperability between different systems easier. Each layer performs specific functions related to network operations. For example, the Physical layer deals with raw bit transmission, while the Application layer handles network services. By separating the complex network system into distinct layers, troubleshooting and development become more manageable, as issues can be identified and resolved in individual layers without affecting the entire system.\",\n",
    "                   \"TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) are two protocols used in the transport layer for data transmission over networks, but they differ significantly in their operations and use cases. TCP is connection-oriented, meaning it establishes a connection between the sender and receiver before transmitting data. It ensures reliable delivery of packets, checks for errors, and guarantees that data arrives in the correct order. Applications such as email, file transfer, and web browsing rely on TCP for this reason. On the other hand, UDP is connectionless, which means it does not guarantee packet delivery, order, or error checking. This makes UDP faster but less reliable. It is used in applications where speed is more critical than reliability, such as video streaming and online gaming, where occasional packet loss is acceptable.\",\n",
    "                   \"Network latency refers to the time it takes for a data packet to travel from its source to its destination. It is often measured in milliseconds (ms) and plays a crucial role in determining the overall performance of a network. High latency can cause noticeable delays in applications, particularly those that require real-time data transmission, such as video conferencing, online gaming, and VoIP. Latency is affected by several factors, including physical distance between devices, routing paths, and the quality of network infrastructure. For example, a packet that has to travel across multiple routers and switches will experience higher latency than one that takes a more direct path. Reducing latency is essential for improving the user experience in applications that demand real-time data.\",\n",
    "                   \"The Domain Name System (DNS) is a hierarchical system that translates human-readable domain names (like www.example.com) into IP addresses, which are necessary for computers to locate and communicate with one another on a network. DNS is essential because users cannot easily remember IP addresses, especially since they can be long strings of numbers. When a user enters a domain name in their web browser, the browser sends a request to a DNS server. The server then searches for the IP address associated with the domain name and returns it to the browser, which can now establish a connection with the correct web server. DNS plays a vital role in making the internet user-friendly by allowing people to use domain names instead of IP addresses.\",\n",
    "                   \"Bandwidth refers to the maximum amount of data that can be transmitted over a network in a given amount of time, usually measured in bits per second (bps). It is a critical factor in determining the speed and performance of a network. Higher bandwidth means more data can be transferred simultaneously, which results in faster download and upload speeds. For example, a network with a bandwidth of 100 Mbps can transfer up to 100 megabits of data per second. Bandwidth is important because it affects how quickly data can be sent and received across a network, making it crucial for applications like video streaming, file transfers, and online gaming, which require large amounts of data to be transferred without delays.\",\n",
    "                   \"Network Address Translation (NAT) is a method used in routers to map multiple private IP addresses within a local network to a single public IP address when communicating with external networks, like the internet. This process hides the internal IP addresses of devices, making it more difficult for potential attackers to target specific devices on the network. By using NAT, only the router’s public IP address is exposed, enhancing security by preventing direct access to internal devices. NAT also conserves public IP addresses, as many devices can share a single public IP. This combination of IP address conservation and security makes NAT an essential feature in modern networking.\",\n",
    "                   \"A Virtual Private Network (VPN) is a secure connection between a user’s device and the internet, allowing data to be transmitted over a public network as if it were a private network. When using a VPN, the data is encrypted, and the user’s IP address is masked, which helps protect privacy and prevent unauthorized access to sensitive information. VPNs are commonly used by remote workers or individuals who want to access region-restricted content, as they provide a way to bypass geographic restrictions. By routing traffic through a secure tunnel, VPNs offer both privacy and security, making them an essential tool for maintaining confidentiality in today’s connected world.\",\n",
    "                   \"An IP address (Internet Protocol address) is a unique numerical label assigned to each device connected to a network that uses the Internet Protocol for communication. It serves two main functions: identifying the host or network interface and providing the location of the device within the network. IP addresses are essential for devices to communicate with one another over the internet, as they provide the means by which data can be routed to the correct destination. Without IP addressing, it would be impossible for devices to send or receive information over a network. IP addresses come in two versions: IPv4, which uses a 32-bit format, and IPv6, which uses a 128-bit format.\",\n",
    "                   \"A firewall is a network security device or software that monitors and controls incoming and outgoing traffic based on predetermined security rules. It acts as a barrier between a trusted internal network and untrusted external networks, such as the internet. Firewalls filter traffic to ensure that only legitimate data passes through while blocking potentially harmful traffic, such as malware or unauthorized access attempts. They can be configured to block certain IP addresses, ports, or specific types of traffic, providing an essential layer of defense against cyber threats. Firewalls are commonly used in both personal and enterprise networks to protect sensitive data.\",\n",
    "                   \"A subnet, or subnetwork, is a smaller, segmented portion of a larger network, created by dividing an IP address range into multiple networks. Subnetting is important because it helps in organizing large networks into smaller, more manageable segments, improving both network performance and security. By dividing a network into subnets, traffic is localized, reducing congestion and allowing for more efficient data routing. It also enhances security by isolating network sections, limiting the impact of security breaches. Subnetting is especially important for businesses with multiple departments or locations, as it enables them to manage their networks more effectively.\"\n",
    "                  ]\n",
    "\n",
    "correct_answer2_2 = [\"The OSI model is a seven-layer architecture that helps standardize and guide the design of networking protocols. These layers are Physical, Data Link, Network, Transport, Session, Presentation, and Application. Each layer serves a specific function in managing network communications. The Physical layer focuses on the hardware aspects, such as cables and switches, while the Application layer provides end-user services like email and file transfer. One of the main benefits of the OSI model is that it allows different hardware and software platforms to communicate with one another, promoting interoperability. It also enables easier troubleshooting because issues can be isolated within individual layers, reducing the complexity of network maintenance.\",\n",
    "                   \"TCP and UDP are both used for sending data across the internet, but their approach to communication is different. TCP is more reliable because it requires acknowledgment for every packet sent. If a packet is lost, TCP will retransmit it, ensuring complete data transfer. However, this reliability comes at the cost of speed, making TCP suitable for applications that require accurate data, such as file transfers or HTTP requests. In contrast, UDP does not require acknowledgments or retransmissions, making it faster but less reliable. It is best used in scenarios like live streaming or VoIP, where real-time transmission is more important than the occasional loss of data.\",\n",
    "                   \"Latency is the delay between the moment a data packet is sent and the moment it is received on the other end. It is influenced by various factors, such as the physical distance between servers, the quality of the transmission medium, and the processing times at intermediate devices like routers and switches. High latency can severely degrade network performance, especially in time-sensitive applications. For example, in online gaming or video conferencing, even a few milliseconds of delay can lead to lag or out-of-sync audio and video. To mitigate latency, techniques such as optimizing routing paths, reducing the number of hops, and using faster transmission technologies like fiber optics can be implemented.\",\n",
    "                   \"DNS stands for Domain Name System and serves as the internet’s address book. It translates domain names into IP addresses so that browsers can load the correct web pages. When a user types a website’s URL into their browser, the request is sent to a DNS resolver, which looks up the IP address associated with the domain. Once the IP address is found, it allows the browser to connect to the web server that hosts the requested site. This system simplifies web navigation for users and provides an organized way to manage and resolve millions of domain names globally, ensuring a seamless browsing experience.\",\n",
    "                   \"In networking, bandwidth is the measure of how much data can be transmitted from one point to another in a specific period, typically expressed in megabits per second (Mbps) or gigabits per second (Gbps). It essentially refers to the capacity of the network connection. The higher the bandwidth, the more data can flow through the network at any given time. High-bandwidth networks are essential for tasks that involve large data volumes, such as streaming HD videos, video conferencing, or downloading large files. Bandwidth is often confused with speed, but it is more about the capacity or volume of data transfer rather than the actual rate at which the data moves.\",\n",
    "                   \"NAT (Network Address Translation) allows devices on a private network to communicate with external networks, such as the internet, by using a single public IP address for multiple internal devices. When a device inside the network sends a request to the internet, NAT replaces the device’s private IP address with the router’s public IP. The router then forwards the request, and any response from the internet is sent back to the router, which translates the public IP back into the device’s private IP. This provides a layer of security by keeping the internal IP addresses hidden from the outside world, reducing the risk of attacks.\",\n",
    "                   \"A VPN, or Virtual Private Network, allows users to create a secure connection to another network over the internet. VPNs are used to protect private web traffic from snooping, interference, and censorship. When connected to a VPN, all internet traffic is routed through an encrypted tunnel, making it difficult for third parties to monitor or intercept the data. VPNs are commonly used by businesses to allow remote employees to access company resources securely, as well as by individuals to access geographically restricted websites and services. The encryption and IP masking features of VPNs provide enhanced security and privacy.\",\n",
    "                   \"IP addressing is a fundamental aspect of networking, enabling devices to communicate over the internet. Every device connected to the internet is assigned a unique IP address, which allows it to send and receive data. IP addresses are crucial because they provide the necessary identification and location information for routing data packets between devices. There are two main types of IP addresses: IPv4 and IPv6. IPv4 is the older version and consists of four sets of numbers, while IPv6 was introduced to accommodate the growing number of devices, using a 128-bit address format and allowing for many more unique addresses. Without IP addressing, devices would not be able to locate or communicate with each other on the network, making it a critical element for any form of digital communication.\",\n",
    "                   \"A firewall is a security mechanism designed to protect networks by controlling the flow of data between a private network and the internet. It operates by enforcing a set of rules that determine whether specific network traffic should be allowed or denied. Firewalls can be implemented as hardware, software, or a combination of both. They inspect incoming and outgoing traffic, blocking unauthorized access and preventing malicious threats such as hackers or viruses from compromising a network. Firewalls are an integral part of any security strategy, as they help safeguard network integrity and protect against external attacks.\",\n",
    "                   \"A subnet is a logical division of a large network into smaller, more manageable pieces. Subnetting is the process of dividing an IP address block into smaller subnets to improve network organization, reduce congestion, and enhance security. By creating subnets, network administrators can control traffic flow more efficiently, isolating different sections of the network and ensuring better performance. This is particularly useful for enterprises with large networks, as subnetting allows them to manage resources more effectively, prevent network overload, and secure sensitive areas by limiting access to specific subnet sections.\"\n",
    "                  ]\n",
    "\n",
    "wrong_answer1_2 = [\"The OSI model consists of four layers, which are Physical, Network, Application, and Presentation. It is a conceptual model designed to explain how software interacts within a single layer. The purpose of the OSI model is to ensure that all networking hardware follows the same manufacturing guidelines, allowing companies to produce compatible devices. Since the OSI model is outdated, it is not commonly used in modern networking systems, where the Internet Protocol Suite is the only important standard.\",\n",
    "                 \"TCP and UDP are both protocols used in the physical layer of the OSI model. TCP is faster than UDP because it doesn’t require any error-checking mechanisms, which makes it perfect for high-speed connections. UDP, on the other hand, is slower but is used when data integrity is critical, such as in financial transactions. Since UDP uses an additional checksum for each packet, it has a higher overhead than TCP.\",\n",
    "                 \"Network latency only occurs when there is congestion in the network and data packets are lost. It primarily affects internal networks and does not have any impact on internet-based applications. Latency is usually measured in bandwidth, and a high bandwidth automatically means low latency. Network latency is often confused with jitter, but they are the same thing.\",\n",
    "                 \"DNS, or Domain Name System, is a type of protocol used exclusively for email servers. It ensures that emails are sent to the correct inbox by converting an email address into a unique email server address. DNS does not affect websites or general internet navigation and is only relevant for routing messages.\",\n",
    "                 \"Bandwidth refers to the speed at which files are downloaded from the internet. It is usually measured in megabytes per second (MBps) and determines how quickly websites load. A higher bandwidth means faster internet speeds, but it has no effect on network capacity. Bandwidth only affects individual devices, not the network as a whole.\",\n",
    "                 \"NAT, or Network Address Translation, is a protocol used to assign static IP addresses to every device within a network. It is primarily used in large networks to ensure that each device has a permanent IP address. NAT does not affect security and is mainly concerned with address allocation, making it irrelevant for small home networks.\",\n",
    "                 \"A Virtual Private Network (VPN) is a tool used to increase internet speed by routing traffic through multiple servers. VPNs eliminate the need for encryption, which is why they provide faster internet speeds. Most people use VPNs to download large files quickly and efficiently. The security benefits of VPNs are minimal, and they are generally only used for improving network performance.\",\n",
    "                 \"An IP address is only used to identify servers, not individual devices, on a network. The server's IP address is shared by all the devices connected to it, and this is how data is sent and received. IP addresses are not necessary for devices like phones or laptops, as they rely on server communication to connect to the internet.\",\n",
    "                 \"A firewall is a physical barrier that is placed around a server to prevent data from escaping. It acts like a physical wall that stops data from being stolen by hackers. If the firewall is breached, data is immediately lost, and the network must be shut down.\",\n",
    "                 \"A subnet is a physical device that connects multiple computers to the internet. It serves as a hub where data is processed before being sent to other parts of the network. Subnetting refers to the act of installing more hubs to increase network speed.\"\n",
    "                ]\n",
    "\n",
    "wrong_answer2_2 = [\"The key difference between TCP and UDP is that TCP works only with IPv6, while UDP works exclusively with IPv4. TCP requires more bandwidth and can only be used in networks with speeds above 1Gbps. UDP is suitable for low-speed networks but often experiences issues with packet loss, making it unreliable for most internet applications. Therefore, TCP is always the preferred choice for any network communication.\",\n",
    "                 \"The kernel acts like a powerful app store for your computer. Different programs you install (like games, web browsers) are individual kernels that the operating system can load and run depending on your needs. This allows for a more modular system and easier updates for specific functionalities.\",\n",
    "                 \"Latency refers to the amount of bandwidth available in a network. It determines how much data can be transmitted at once. A network with high latency will be able to send more data, making it ideal for video streaming and large file transfers. If a network experiences low latency, it may struggle to keep up with the demands of high-bandwidth applications, leading to poor performance.\",\n",
    "                 \"The Domain Name System (DNS) works by converting email addresses into IP addresses. Every time a person sends an email, the DNS server ensures that the email address is converted into the correct IP address of the receiving server. Without DNS, emails would not reach their intended recipients. However, DNS is not used for regular web browsing, which relies on a different system.\",\n",
    "                 \"Bandwidth is the amount of data that a single device can handle at once. It is determined by the hardware specifications of the device, such as its RAM and processor speed. High-end devices have more bandwidth, allowing them to access faster internet connections, while low-end devices struggle with slower speeds. Bandwidth is not related to the network itself but rather the devices that connect to it.\",\n",
    "                 \"Network Address Translation (NAT) is a feature that improves the speed of a network by optimizing the routing process. It uses algorithms to identify the quickest path for data to travel, reducing latency. While it is a useful tool for high-speed networks, NAT has no security benefits and does not impact how IP addresses are managed within a network\",\n",
    "                 \"VPN stands for Virtual Public Network, and it is a tool used to make public Wi-Fi networks faster and more reliable. When you connect to a VPN, you are granted access to a faster internet connection by bypassing local internet service providers. VPNs are primarily used to reduce lag in video games and have no encryption or privacy features.\",\n",
    "                 \"IP addressing is a system that assigns the same number to every device on a network. It helps to identify the total number of devices but doesn’t differentiate between individual ones. This system is outdated and has been replaced by a method that assigns different identification numbers to devices based on their physical location instead.\",\n",
    "                 \"Firewalls are tools that boost internet speed by directing traffic to less congested routes. They do not offer any security benefits but are essential for speeding up downloads and browsing speeds. A firewall works by splitting the data between multiple pathways, allowing for faster data transfer without concern for safety.\",\n",
    "                 \"Subnetting is the practice of combining multiple networks into one larger network. This helps improve communication across different locations, as all devices share the same IP address. Subnets are used to create larger networks to save on infrastructure costs and reduce the complexity of managing multiple addresses.\"\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YE4OzqcJ_bEg",
    "outputId": "4147956e-17fc-4e1a-cac2-1525ef72ef83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import nltk\n",
    "# from gensim.matutils import softcossim\n",
    "\n",
    "# from gensim import similarities\n",
    "from gensim import corpora\n",
    "from gensim.models import FastText\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Download stopwords if you haven't already\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "\n",
    "# Tokenization and cleaning\n",
    "def preprocess(sentence):\n",
    "    # Lowercase and remove punctuation\n",
    "    sentence = sentence.lower()\n",
    "    # sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "\n",
    "    # Tokenize\n",
    "    words = word_tokenize(sentence)\n",
    "\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "def sentence_to_vec(tokens, model):\n",
    "    # Filter words that are in the Word2Vec vocabulary\n",
    "    valid_words = [word for word in tokens if word in model]\n",
    "\n",
    "    # If there are no valid words, return a zero vector\n",
    "    if not valid_words:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "    # Compute the average vector\n",
    "    word_vectors = [model[word] for word in valid_words]\n",
    "    sentence_vector = np.mean(word_vectors, axis=0)\n",
    "\n",
    "    return sentence_vector\n",
    "\n",
    "\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZm978MzQ8xQ"
   },
   "outputs": [],
   "source": [
    "from gensim.similarities import SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex\n",
    "\n",
    "def compute_scm(tokens1, tokens2, model):\n",
    "\n",
    "    dictionary = corpora.Dictionary([tokens1, tokens2])\n",
    "\n",
    "    tokens1 = dictionary.doc2bow(tokens1)\n",
    "    tokens2 = dictionary.doc2bow(tokens2)\n",
    "\n",
    "    # print(\"termsim_index\")\n",
    "    termsim_index = WordEmbeddingSimilarityIndex(model)\n",
    "\n",
    "    # print(\"termsim_matrix\")\n",
    "    termsim_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary)\n",
    "\n",
    "    # print(\"similarity\")\n",
    "    similarity = termsim_matrix.inner_product(tokens1, tokens2, normalized=(True, True))\n",
    "\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuNj2wS_AjOd",
    "outputId": "b2029056-e085-440f-f6a8-daa413638305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
      "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# word2vec_model = [KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True),KeyedVectors.load_word2vec_format('cc.en.300.bin', binary=True)]\n",
    "# import gensim.downloader as api\n",
    "word2vec_model = [api.load('word2vec-google-news-300'),api.load('glove-wiki-gigaword-100'),api.load('fasttext-wiki-news-subwords-300')]\n",
    "\n",
    "model = ['word2vec-google-news-300','glove-wiki-gigaword-100','fasttext-wiki-news-subwords-300']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6NPMef_L79p"
   },
   "outputs": [],
   "source": [
    "# word2vec_model[1].wmdistance(\"see\",\"sea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6q9tt9mILQp",
    "outputId": "1294546b-98f1-4333-e676-e004db19a45a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:27<00:00,  2.27it/s]\n",
      "100%|██████████| 60/60 [00:28<00:00,  2.10it/s]\n",
      "100%|██████████| 62/62 [00:27<00:00,  2.24it/s]\n",
      "100%|██████████| 45/45 [00:15<00:00,  2.92it/s]\n",
      "100%|██████████| 50/50 [00:18<00:00,  2.77it/s]\n",
      "100%|██████████| 38/38 [00:13<00:00,  2.88it/s]\n",
      "100%|██████████| 49/49 [00:22<00:00,  2.16it/s]\n",
      "100%|██████████| 52/52 [00:17<00:00,  2.90it/s]\n",
      "100%|██████████| 47/47 [00:17<00:00,  2.76it/s]\n",
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "100%|██████████| 52/52 [00:18<00:00,  2.76it/s]\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.93it/s]\n",
      "100%|██████████| 68/68 [00:24<00:00,  2.78it/s]\n",
      "100%|██████████| 43/43 [00:15<00:00,  2.69it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.68it/s]\n",
      "100%|██████████| 38/38 [00:14<00:00,  2.65it/s]\n",
      "100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n",
      "100%|██████████| 32/32 [00:11<00:00,  2.69it/s]\n",
      "100%|██████████| 39/39 [00:13<00:00,  2.97it/s]\n",
      "100%|██████████| 39/39 [00:13<00:00,  2.93it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.85it/s]\n",
      "100%|██████████| 29/29 [00:08<00:00,  3.56it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.74it/s]\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.11it/s]\n",
      "100%|██████████| 28/28 [00:08<00:00,  3.18it/s]\n",
      "100%|██████████| 94/94 [00:33<00:00,  2.77it/s]\n",
      "100%|██████████| 98/98 [00:34<00:00,  2.88it/s]\n",
      "100%|██████████| 102/102 [00:38<00:00,  2.65it/s]\n",
      "100%|██████████| 99/99 [00:36<00:00,  2.74it/s]\n",
      "100%|██████████| 102/102 [00:38<00:00,  2.65it/s]\n",
      "100%|██████████| 124/124 [00:45<00:00,  2.72it/s]\n",
      "100%|██████████| 120/120 [00:44<00:00,  2.69it/s]\n",
      "100%|██████████| 131/131 [00:49<00:00,  2.66it/s]\n",
      "100%|██████████| 113/113 [00:43<00:00,  2.62it/s]\n",
      "100%|██████████| 120/120 [00:44<00:00,  2.70it/s]\n",
      "100%|██████████| 110/110 [00:42<00:00,  2.61it/s]\n",
      "100%|██████████| 104/104 [00:38<00:00,  2.68it/s]\n",
      "100%|██████████| 104/104 [00:38<00:00,  2.70it/s]\n",
      "100%|██████████| 116/116 [00:42<00:00,  2.75it/s]\n",
      "100%|██████████| 113/113 [00:40<00:00,  2.78it/s]\n",
      "100%|██████████| 111/111 [00:41<00:00,  2.65it/s]\n",
      "100%|██████████| 123/123 [00:45<00:00,  2.68it/s]\n",
      "100%|██████████| 121/121 [00:45<00:00,  2.66it/s]\n",
      "100%|██████████| 122/122 [00:44<00:00,  2.75it/s]\n",
      "100%|██████████| 119/119 [00:45<00:00,  2.63it/s]\n",
      "100%|██████████| 90/90 [00:33<00:00,  2.72it/s]\n",
      "100%|██████████| 86/86 [00:31<00:00,  2.76it/s]\n",
      "100%|██████████| 90/90 [00:31<00:00,  2.83it/s]\n",
      "100%|██████████| 100/100 [00:37<00:00,  2.69it/s]\n",
      "100%|██████████| 106/106 [00:39<00:00,  2.70it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 35.04it/s]\n",
      "100%|██████████| 60/60 [00:01<00:00, 49.18it/s]\n",
      "100%|██████████| 62/62 [00:01<00:00, 52.34it/s]\n",
      "100%|██████████| 45/45 [00:00<00:00, 50.80it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 53.88it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 51.02it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 51.73it/s]\n",
      "100%|██████████| 52/52 [00:01<00:00, 50.68it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 51.63it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 51.70it/s]\n",
      "100%|██████████| 52/52 [00:01<00:00, 50.07it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 31.79it/s]\n",
      "100%|██████████| 68/68 [00:02<00:00, 31.90it/s]\n",
      "100%|██████████| 43/43 [00:00<00:00, 50.86it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 50.57it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 50.43it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 52.03it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 48.82it/s]\n",
      "100%|██████████| 39/39 [00:00<00:00, 50.92it/s]\n",
      "100%|██████████| 39/39 [00:00<00:00, 50.64it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 51.24it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 53.74it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 51.93it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 53.01it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 53.69it/s]\n",
      "100%|██████████| 94/94 [00:02<00:00, 45.72it/s]\n",
      "100%|██████████| 98/98 [00:03<00:00, 30.89it/s]\n",
      "100%|██████████| 102/102 [00:02<00:00, 47.42it/s]\n",
      "100%|██████████| 99/99 [00:02<00:00, 49.04it/s]\n",
      "100%|██████████| 102/102 [00:02<00:00, 50.22it/s]\n",
      "100%|██████████| 124/124 [00:02<00:00, 50.62it/s]\n",
      "100%|██████████| 120/120 [00:02<00:00, 43.11it/s]\n",
      "100%|██████████| 131/131 [00:03<00:00, 35.04it/s]\n",
      "100%|██████████| 113/113 [00:02<00:00, 52.06it/s]\n",
      "100%|██████████| 120/120 [00:02<00:00, 50.15it/s]\n",
      "100%|██████████| 110/110 [00:02<00:00, 51.93it/s]\n",
      "100%|██████████| 104/104 [00:02<00:00, 49.93it/s]\n",
      "100%|██████████| 104/104 [00:03<00:00, 34.22it/s]\n",
      "100%|██████████| 116/116 [00:02<00:00, 40.59it/s]\n",
      "100%|██████████| 113/113 [00:02<00:00, 51.40it/s]\n",
      "100%|██████████| 111/111 [00:02<00:00, 49.32it/s]\n",
      "100%|██████████| 123/123 [00:02<00:00, 51.19it/s]\n",
      "100%|██████████| 121/121 [00:02<00:00, 45.51it/s]\n",
      "100%|██████████| 122/122 [00:03<00:00, 32.60it/s]\n",
      "100%|██████████| 119/119 [00:02<00:00, 50.73it/s]\n",
      "100%|██████████| 90/90 [00:01<00:00, 51.78it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 51.66it/s]\n",
      "100%|██████████| 90/90 [00:01<00:00, 51.65it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.52it/s]\n",
      "100%|██████████| 106/106 [00:03<00:00, 32.73it/s]\n",
      "100%|██████████| 63/63 [00:07<00:00,  8.16it/s]\n",
      "100%|██████████| 60/60 [00:08<00:00,  6.88it/s]\n",
      "100%|██████████| 62/62 [00:07<00:00,  8.50it/s]\n",
      "100%|██████████| 45/45 [00:06<00:00,  6.54it/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.56it/s]\n",
      "100%|██████████| 38/38 [00:05<00:00,  6.66it/s]\n",
      "100%|██████████| 49/49 [00:06<00:00,  8.12it/s]\n",
      "100%|██████████| 52/52 [00:07<00:00,  7.31it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.71it/s]\n",
      "100%|██████████| 49/49 [00:05<00:00,  8.46it/s]\n",
      "100%|██████████| 52/52 [00:07<00:00,  6.63it/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.48it/s]\n",
      "100%|██████████| 68/68 [00:09<00:00,  7.54it/s]\n",
      "100%|██████████| 43/43 [00:05<00:00,  7.23it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.76it/s]\n",
      "100%|██████████| 38/38 [00:05<00:00,  7.57it/s]\n",
      "100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n",
      "100%|██████████| 32/32 [00:03<00:00,  8.16it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  7.64it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  6.85it/s]\n",
      "100%|██████████| 27/27 [00:03<00:00,  8.34it/s]\n",
      "100%|██████████| 29/29 [00:03<00:00,  8.18it/s]\n",
      "100%|██████████| 23/23 [00:04<00:00,  5.70it/s]\n",
      "100%|██████████| 30/30 [00:03<00:00,  7.96it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.32it/s]\n",
      "100%|██████████| 94/94 [00:12<00:00,  7.44it/s]\n",
      "100%|██████████| 98/98 [00:13<00:00,  7.44it/s]\n",
      "100%|██████████| 102/102 [00:13<00:00,  7.56it/s]\n",
      "100%|██████████| 99/99 [00:13<00:00,  7.47it/s]\n",
      "100%|██████████| 102/102 [00:13<00:00,  7.51it/s]\n",
      "100%|██████████| 124/124 [00:16<00:00,  7.60it/s]\n",
      "100%|██████████| 120/120 [00:15<00:00,  7.64it/s]\n",
      "100%|██████████| 131/131 [00:18<00:00,  6.91it/s]\n",
      "100%|██████████| 113/113 [00:15<00:00,  7.28it/s]\n",
      "100%|██████████| 120/120 [00:16<00:00,  7.30it/s]\n",
      "100%|██████████| 110/110 [00:14<00:00,  7.61it/s]\n",
      "100%|██████████| 104/104 [00:13<00:00,  7.43it/s]\n",
      "100%|██████████| 104/104 [00:13<00:00,  7.55it/s]\n",
      "100%|██████████| 116/116 [00:15<00:00,  7.67it/s]\n",
      "100%|██████████| 113/113 [00:14<00:00,  7.57it/s]\n",
      "100%|██████████| 111/111 [00:14<00:00,  7.51it/s]\n",
      "100%|██████████| 123/123 [00:16<00:00,  7.61it/s]\n",
      "100%|██████████| 121/121 [00:15<00:00,  7.62it/s]\n",
      "100%|██████████| 122/122 [00:16<00:00,  7.25it/s]\n",
      "100%|██████████| 119/119 [00:17<00:00,  6.72it/s]\n",
      "100%|██████████| 90/90 [00:12<00:00,  7.41it/s]\n",
      "100%|██████████| 86/86 [00:10<00:00,  7.98it/s]\n",
      "100%|██████████| 90/90 [00:12<00:00,  7.43it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.41it/s]\n",
      "100%|██████████| 106/106 [00:14<00:00,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_correct_answer1 = []\n",
    "preprocess_correct_answer2 = []\n",
    "preprocess_wrong_answer1   = []\n",
    "preprocess_wrong_answer2   = []\n",
    "\n",
    "cosine__similarity_1 = []\n",
    "wmd_distance_similarity_1 = []\n",
    "soft_cosine_1 = []\n",
    "\n",
    "for i in range(len(question_1)):\n",
    "  preprocess_correct_answer1.append(preprocess(correct_answer1_1[i]))\n",
    "  preprocess_correct_answer2.append(preprocess(correct_answer2_1[i]))\n",
    "  preprocess_wrong_answer1.append(preprocess(wrong_answer1_1[i]))\n",
    "  preprocess_wrong_answer2.append(preprocess(wrong_answer2_1[i]))\n",
    "\n",
    "\n",
    "k=0\n",
    "for i in word2vec_model:\n",
    "\n",
    "  # print(model[k])\n",
    "  for j in range(len(question_1)):\n",
    "\n",
    "    # print(\"similarity\")\n",
    "    vec1 = sentence_to_vec(preprocess_correct_answer1[j], i)\n",
    "    vec2 = sentence_to_vec(preprocess_correct_answer2[j], i)\n",
    "    vec3 = sentence_to_vec(preprocess_wrong_answer1[j], i)\n",
    "    vec4 = sentence_to_vec(preprocess_wrong_answer2[j], i)\n",
    "\n",
    "\n",
    "    cosine_similarity1 =  cosine_similarity(vec1, vec2)\n",
    "    cosine_similarity2 =  cosine_similarity(vec1, vec3)\n",
    "    cosine_similarity3 =  cosine_similarity(vec1, vec4)\n",
    "\n",
    "    cosine_similarity4 =  cosine_similarity(vec2, vec3)\n",
    "    cosine_similarity5 =  cosine_similarity(vec2, vec4)\n",
    "\n",
    "    cosine__similarity_1.append([model[k],j,cosine_similarity1, cosine_similarity2, cosine_similarity3, cosine_similarity4, cosine_similarity5])\n",
    "# from gensim.similarities import WmdSimilarity\n",
    "    # Compute WMD\n",
    "    # print(\"Compute WMD\")\n",
    "    wmd_distance1 = i.wmdistance(preprocess_correct_answer1[j], preprocess_correct_answer2[j])\n",
    "    wmd_similarity1 = 1 / (1 + wmd_distance1)\n",
    "    wmd_distance2 = i.wmdistance(preprocess_correct_answer1[j], preprocess_wrong_answer1[j])\n",
    "    wmd_similarity2 = 1 / (1 + wmd_distance2)\n",
    "    wmd_distance3 = i.wmdistance(preprocess_correct_answer1[j], preprocess_wrong_answer2[j])\n",
    "    wmd_similarity3 = 1 / (1 + wmd_distance3)\n",
    "\n",
    "    wmd_distance4 = i.wmdistance(preprocess_correct_answer2[j], preprocess_wrong_answer1[j])\n",
    "    wmd_similarity4 = 1 / (1 + wmd_distance4)\n",
    "    wmd_distance5 = i.wmdistance(preprocess_correct_answer2[j], preprocess_wrong_answer2[j])\n",
    "    wmd_similarity5 = 1 / (1 + wmd_distance5)\n",
    "\n",
    "    wmd_distance_similarity_1.append([model[k],j,wmd_similarity1, wmd_similarity2, wmd_similarity3, wmd_similarity4, wmd_similarity5])\n",
    "\n",
    "\n",
    "    # Soft Cosine Measure\n",
    "    # print(\"Soft Cosine Measure\")\n",
    "    soft_cosine1 = compute_scm(preprocess_correct_answer1[j], preprocess_correct_answer2[j],i)\n",
    "    soft_cosine2 = compute_scm(preprocess_correct_answer1[j], preprocess_wrong_answer1[j],i)\n",
    "    soft_cosine3 = compute_scm(preprocess_correct_answer1[j], preprocess_wrong_answer2[j],i)\n",
    "\n",
    "    soft_cosine4 = compute_scm(preprocess_correct_answer2[j], preprocess_wrong_answer1[j],i)\n",
    "    soft_cosine5 = compute_scm(preprocess_correct_answer2[j], preprocess_wrong_answer2[j],i)\n",
    "\n",
    "    soft_cosine_1.append([model[k],j,soft_cosine1, soft_cosine2, soft_cosine3, soft_cosine4, soft_cosine5])\n",
    "  # print(model[k])\n",
    "  k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9j0YPQpkkqB",
    "outputId": "11542546-918e-44e1-ef77-62a6e7dc5307"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:41<00:00,  2.58it/s]\n",
      "100%|██████████| 99/99 [00:35<00:00,  2.76it/s]\n",
      "100%|██████████| 97/97 [00:34<00:00,  2.80it/s]\n",
      "100%|██████████| 89/89 [00:32<00:00,  2.76it/s]\n",
      "100%|██████████| 90/90 [00:33<00:00,  2.69it/s]\n",
      "100%|██████████| 102/102 [00:37<00:00,  2.70it/s]\n",
      "100%|██████████| 88/88 [00:31<00:00,  2.83it/s]\n",
      "100%|██████████| 94/94 [00:34<00:00,  2.72it/s]\n",
      "100%|██████████| 77/77 [00:27<00:00,  2.81it/s]\n",
      "100%|██████████| 80/80 [00:29<00:00,  2.75it/s]\n",
      "100%|██████████| 97/97 [00:34<00:00,  2.78it/s]\n",
      "100%|██████████| 82/82 [00:30<00:00,  2.67it/s]\n",
      "100%|██████████| 87/87 [00:31<00:00,  2.80it/s]\n",
      "100%|██████████| 79/79 [00:28<00:00,  2.76it/s]\n",
      "100%|██████████| 83/83 [00:29<00:00,  2.80it/s]\n",
      "100%|██████████| 88/88 [00:30<00:00,  2.85it/s]\n",
      "100%|██████████| 75/75 [00:26<00:00,  2.78it/s]\n",
      "100%|██████████| 77/77 [00:28<00:00,  2.68it/s]\n",
      "100%|██████████| 69/69 [00:25<00:00,  2.66it/s]\n",
      "100%|██████████| 75/75 [00:27<00:00,  2.73it/s]\n",
      "100%|██████████| 93/93 [00:34<00:00,  2.73it/s]\n",
      "100%|██████████| 71/71 [00:24<00:00,  2.89it/s]\n",
      "100%|██████████| 79/79 [00:27<00:00,  2.86it/s]\n",
      "100%|██████████| 72/72 [00:26<00:00,  2.77it/s]\n",
      "100%|██████████| 77/77 [00:28<00:00,  2.72it/s]\n",
      "100%|██████████| 76/76 [00:27<00:00,  2.77it/s]\n",
      "100%|██████████| 71/71 [00:25<00:00,  2.76it/s]\n",
      "100%|██████████| 74/74 [00:26<00:00,  2.80it/s]\n",
      "100%|██████████| 62/62 [00:21<00:00,  2.91it/s]\n",
      "100%|██████████| 65/65 [00:23<00:00,  2.77it/s]\n",
      "100%|██████████| 87/87 [00:30<00:00,  2.83it/s]\n",
      "100%|██████████| 79/79 [00:29<00:00,  2.69it/s]\n",
      "100%|██████████| 77/77 [00:27<00:00,  2.83it/s]\n",
      "100%|██████████| 79/79 [00:28<00:00,  2.77it/s]\n",
      "100%|██████████| 74/74 [00:27<00:00,  2.72it/s]\n",
      "100%|██████████| 86/86 [00:30<00:00,  2.82it/s]\n",
      "100%|██████████| 69/69 [00:23<00:00,  2.88it/s]\n",
      "100%|██████████| 74/74 [00:25<00:00,  2.87it/s]\n",
      "100%|██████████| 76/76 [00:28<00:00,  2.63it/s]\n",
      "100%|██████████| 78/78 [00:28<00:00,  2.77it/s]\n",
      "100%|██████████| 84/84 [00:31<00:00,  2.65it/s]\n",
      "100%|██████████| 72/72 [00:27<00:00,  2.63it/s]\n",
      "100%|██████████| 79/79 [00:29<00:00,  2.64it/s]\n",
      "100%|██████████| 66/66 [00:25<00:00,  2.62it/s]\n",
      "100%|██████████| 73/73 [00:28<00:00,  2.60it/s]\n",
      "100%|██████████| 78/78 [00:30<00:00,  2.59it/s]\n",
      "100%|██████████| 65/65 [00:24<00:00,  2.63it/s]\n",
      "100%|██████████| 67/67 [00:25<00:00,  2.67it/s]\n",
      "100%|██████████| 69/69 [00:25<00:00,  2.71it/s]\n",
      "100%|██████████| 70/70 [00:26<00:00,  2.63it/s]\n",
      "100%|██████████| 107/107 [00:02<00:00, 37.75it/s]\n",
      "100%|██████████| 99/99 [00:02<00:00, 33.65it/s]\n",
      "100%|██████████| 97/97 [00:01<00:00, 50.82it/s]\n",
      "100%|██████████| 89/89 [00:01<00:00, 51.44it/s]\n",
      "100%|██████████| 90/90 [00:01<00:00, 51.83it/s]\n",
      "100%|██████████| 102/102 [00:02<00:00, 50.66it/s]\n",
      "100%|██████████| 88/88 [00:01<00:00, 50.19it/s]\n",
      "100%|██████████| 94/94 [00:02<00:00, 33.26it/s]\n",
      "100%|██████████| 77/77 [00:02<00:00, 36.51it/s]\n",
      "100%|██████████| 80/80 [00:01<00:00, 49.07it/s]\n",
      "100%|██████████| 97/97 [00:01<00:00, 50.21it/s]\n",
      "100%|██████████| 82/82 [00:01<00:00, 48.78it/s]\n",
      "100%|██████████| 87/87 [00:01<00:00, 47.96it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 50.08it/s]\n",
      "100%|██████████| 83/83 [00:02<00:00, 37.21it/s]\n",
      "100%|██████████| 88/88 [00:02<00:00, 33.05it/s]\n",
      "100%|██████████| 75/75 [00:01<00:00, 51.29it/s]\n",
      "100%|██████████| 77/77 [00:01<00:00, 50.71it/s]\n",
      "100%|██████████| 69/69 [00:01<00:00, 50.76it/s]\n",
      "100%|██████████| 75/75 [00:01<00:00, 49.58it/s]\n",
      "100%|██████████| 93/93 [00:01<00:00, 50.37it/s]\n",
      "100%|██████████| 71/71 [00:01<00:00, 50.16it/s]\n",
      "100%|██████████| 79/79 [00:02<00:00, 34.78it/s]\n",
      "100%|██████████| 72/72 [00:02<00:00, 31.48it/s]\n",
      "100%|██████████| 77/77 [00:01<00:00, 49.14it/s]\n",
      "100%|██████████| 76/76 [00:01<00:00, 49.69it/s]\n",
      "100%|██████████| 71/71 [00:01<00:00, 49.74it/s]\n",
      "100%|██████████| 74/74 [00:01<00:00, 50.25it/s]\n",
      "100%|██████████| 62/62 [00:01<00:00, 51.64it/s]\n",
      "100%|██████████| 65/65 [00:01<00:00, 51.15it/s]\n",
      "100%|██████████| 87/87 [00:01<00:00, 44.60it/s]\n",
      "100%|██████████| 79/79 [00:02<00:00, 28.23it/s]\n",
      "100%|██████████| 77/77 [00:02<00:00, 28.99it/s]\n",
      "100%|██████████| 79/79 [00:02<00:00, 37.88it/s]\n",
      "100%|██████████| 74/74 [00:01<00:00, 50.66it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 51.07it/s]\n",
      "100%|██████████| 69/69 [00:01<00:00, 50.19it/s]\n",
      "100%|██████████| 74/74 [00:01<00:00, 50.96it/s]\n",
      "100%|██████████| 76/76 [00:01<00:00, 50.74it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 45.89it/s]\n",
      "100%|██████████| 84/84 [00:02<00:00, 29.83it/s]\n",
      "100%|██████████| 72/72 [00:01<00:00, 47.27it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 47.47it/s]\n",
      "100%|██████████| 66/66 [00:01<00:00, 50.19it/s]\n",
      "100%|██████████| 73/73 [00:01<00:00, 48.92it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 52.46it/s]\n",
      "100%|██████████| 65/65 [00:01<00:00, 52.37it/s]\n",
      "100%|██████████| 67/67 [00:01<00:00, 51.87it/s]\n",
      "100%|██████████| 69/69 [00:02<00:00, 32.04it/s]\n",
      "100%|██████████| 70/70 [00:02<00:00, 33.60it/s]\n",
      "100%|██████████| 107/107 [00:14<00:00,  7.39it/s]\n",
      "100%|██████████| 99/99 [00:12<00:00,  7.66it/s]\n",
      "100%|██████████| 97/97 [00:12<00:00,  7.75it/s]\n",
      "100%|██████████| 89/89 [00:11<00:00,  7.74it/s]\n",
      "100%|██████████| 90/90 [00:12<00:00,  7.39it/s]\n",
      "100%|██████████| 102/102 [00:13<00:00,  7.53it/s]\n",
      "100%|██████████| 88/88 [00:11<00:00,  7.44it/s]\n",
      "100%|██████████| 94/94 [00:12<00:00,  7.38it/s]\n",
      "100%|██████████| 77/77 [00:10<00:00,  7.36it/s]\n",
      "100%|██████████| 80/80 [00:09<00:00,  8.14it/s]\n",
      "100%|██████████| 97/97 [00:13<00:00,  7.38it/s]\n",
      "100%|██████████| 82/82 [00:11<00:00,  7.29it/s]\n",
      "100%|██████████| 87/87 [00:11<00:00,  7.25it/s]\n",
      "100%|██████████| 79/79 [00:12<00:00,  6.49it/s]\n",
      "100%|██████████| 83/83 [00:10<00:00,  7.76it/s]\n",
      "100%|██████████| 88/88 [00:11<00:00,  7.65it/s]\n",
      "100%|██████████| 75/75 [00:10<00:00,  7.27it/s]\n",
      "100%|██████████| 77/77 [00:10<00:00,  7.21it/s]\n",
      "100%|██████████| 69/69 [00:08<00:00,  8.18it/s]\n",
      "100%|██████████| 75/75 [00:10<00:00,  7.21it/s]\n",
      "100%|██████████| 93/93 [00:12<00:00,  7.48it/s]\n",
      "100%|██████████| 71/71 [00:09<00:00,  7.15it/s]\n",
      "100%|██████████| 79/79 [00:09<00:00,  8.27it/s]\n",
      "100%|██████████| 72/72 [00:09<00:00,  7.29it/s]\n",
      "100%|██████████| 77/77 [00:10<00:00,  7.31it/s]\n",
      "100%|██████████| 76/76 [00:10<00:00,  7.48it/s]\n",
      "100%|██████████| 71/71 [00:09<00:00,  7.85it/s]\n",
      "100%|██████████| 74/74 [00:10<00:00,  6.98it/s]\n",
      "100%|██████████| 62/62 [00:07<00:00,  7.80it/s]\n",
      "100%|██████████| 65/65 [00:08<00:00,  7.28it/s]\n",
      "100%|██████████| 87/87 [00:11<00:00,  7.49it/s]\n",
      "100%|██████████| 79/79 [00:10<00:00,  7.36it/s]\n",
      "100%|██████████| 77/77 [00:10<00:00,  7.39it/s]\n",
      "100%|██████████| 79/79 [00:10<00:00,  7.44it/s]\n",
      "100%|██████████| 74/74 [00:10<00:00,  7.28it/s]\n",
      "100%|██████████| 86/86 [00:11<00:00,  7.34it/s]\n",
      "100%|██████████| 69/69 [00:08<00:00,  8.19it/s]\n",
      "100%|██████████| 74/74 [00:10<00:00,  7.25it/s]\n",
      "100%|██████████| 76/76 [00:10<00:00,  7.06it/s]\n",
      "100%|██████████| 78/78 [00:10<00:00,  7.56it/s]\n",
      "100%|██████████| 84/84 [00:10<00:00,  7.77it/s]\n",
      "100%|██████████| 72/72 [00:10<00:00,  7.11it/s]\n",
      "100%|██████████| 79/79 [00:10<00:00,  7.21it/s]\n",
      "100%|██████████| 66/66 [00:07<00:00,  8.28it/s]\n",
      "100%|██████████| 73/73 [00:10<00:00,  7.17it/s]\n",
      "100%|██████████| 78/78 [00:10<00:00,  7.37it/s]\n",
      "100%|██████████| 65/65 [00:08<00:00,  7.74it/s]\n",
      "100%|██████████| 67/67 [00:09<00:00,  7.40it/s]\n",
      "100%|██████████| 69/69 [00:09<00:00,  7.07it/s]\n",
      "100%|██████████| 70/70 [00:08<00:00,  8.06it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_correct_answer1 = []\n",
    "preprocess_correct_answer2 = []\n",
    "preprocess_wrong_answer1   = []\n",
    "preprocess_wrong_answer2   = []\n",
    "\n",
    "cosine__similarity_2 = []\n",
    "wmd_distance_similarity_2 = []\n",
    "soft_cosine_2 = []\n",
    "\n",
    "for i in range(len(question_2)):\n",
    "  preprocess_correct_answer1.append(preprocess(correct_answer1_2[i]))\n",
    "  preprocess_correct_answer2.append(preprocess(correct_answer2_2[i]))\n",
    "  preprocess_wrong_answer1.append(preprocess(wrong_answer1_2[i]))\n",
    "  preprocess_wrong_answer2.append(preprocess(wrong_answer2_2[i]))\n",
    "\n",
    "\n",
    "k=0\n",
    "for i in word2vec_model:\n",
    "\n",
    "  # print(model[k])\n",
    "  for j in range(len(question_2)):\n",
    "\n",
    "    # print(\"similarity\")\n",
    "    vec1 = sentence_to_vec(preprocess_correct_answer1[j], i)\n",
    "    vec2 = sentence_to_vec(preprocess_correct_answer2[j], i)\n",
    "    vec3 = sentence_to_vec(preprocess_wrong_answer1[j], i)\n",
    "    vec4 = sentence_to_vec(preprocess_wrong_answer2[j], i)\n",
    "\n",
    "\n",
    "    cosine_similarity1 =  cosine_similarity(vec1, vec2)\n",
    "    cosine_similarity2 =  cosine_similarity(vec1, vec3)\n",
    "    cosine_similarity3 =  cosine_similarity(vec1, vec4)\n",
    "\n",
    "    cosine_similarity4 =  cosine_similarity(vec2, vec3)\n",
    "    cosine_similarity5 =  cosine_similarity(vec2, vec4)\n",
    "\n",
    "    cosine__similarity_2.append([model[k],j,cosine_similarity1, cosine_similarity2, cosine_similarity3, cosine_similarity4, cosine_similarity5])\n",
    "# from gensim.similarities import WmdSimilarity\n",
    "    # Compute WMD\n",
    "    # print(\"Compute WMD\")\n",
    "    wmd_distance1 = i.wmdistance(preprocess_correct_answer1[j], preprocess_correct_answer2[j])\n",
    "    wmd_similarity1 = 1 / (1 + wmd_distance1)\n",
    "    wmd_distance2 = i.wmdistance(preprocess_correct_answer1[j], preprocess_wrong_answer1[j])\n",
    "    wmd_similarity2 = 1 / (1 + wmd_distance2)\n",
    "    wmd_distance3 = i.wmdistance(preprocess_correct_answer1[j], preprocess_wrong_answer2[j])\n",
    "    wmd_similarity3 = 1 / (1 + wmd_distance3)\n",
    "\n",
    "    wmd_distance4 = i.wmdistance(preprocess_correct_answer2[j], preprocess_wrong_answer1[j])\n",
    "    wmd_similarity4 = 1 / (1 + wmd_distance4)\n",
    "    wmd_distance5 = i.wmdistance(preprocess_correct_answer2[j], preprocess_wrong_answer2[j])\n",
    "    wmd_similarity5 = 1 / (1 + wmd_distance5)\n",
    "\n",
    "    wmd_distance_similarity_2.append([model[k],j,wmd_similarity1, wmd_similarity2, wmd_similarity3, wmd_similarity4, wmd_similarity5])\n",
    "\n",
    "\n",
    "    # Soft Cosine Measure\n",
    "    # print(\"Soft Cosine Measure\")\n",
    "    soft_cosine1 = compute_scm(preprocess_correct_answer1[j], preprocess_correct_answer2[j],i)\n",
    "    soft_cosine2 = compute_scm(preprocess_correct_answer1[j], preprocess_wrong_answer1[j],i)\n",
    "    soft_cosine3 = compute_scm(preprocess_correct_answer1[j], preprocess_wrong_answer2[j],i)\n",
    "\n",
    "    soft_cosine4 = compute_scm(preprocess_correct_answer2[j], preprocess_wrong_answer1[j],i)\n",
    "    soft_cosine5 = compute_scm(preprocess_correct_answer2[j], preprocess_wrong_answer2[j],i)\n",
    "\n",
    "    soft_cosine_2.append([model[k],j,soft_cosine1, soft_cosine2, soft_cosine3, soft_cosine4, soft_cosine5])\n",
    "  # print(model[k])\n",
    "  k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bm5X_-uBrQ5n",
    "outputId": "47be3bee-7104-4a23-9325-7051fa53f7d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity question1\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| Model                           |   Question no |   Similarity c1 and c2 |   Similarity c1 and w1 |   Similarity c1 and w2 |   Similarity c2 and w1 |   Similarity c2 and w2 |\n",
      "+=================================+===============+========================+========================+========================+========================+========================+\n",
      "| word2vec-google-news-300        |             0 |               0.841465 |               0.803439 |               0.780714 |               0.856825 |               0.825178 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             1 |               0.926427 |               0.691273 |               0.79203  |               0.681818 |               0.783271 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             2 |               0.859359 |               0.810821 |               0.770612 |               0.646423 |               0.699343 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             3 |               0.795487 |               0.700292 |               0.693516 |               0.717612 |               0.633304 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             4 |               0.809285 |               0.648144 |               0.682935 |               0.715382 |               0.713394 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             5 |               0.94498  |               0.906212 |               0.86624  |               0.882311 |               0.872348 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             6 |               0.960806 |               0.939703 |               0.891043 |               0.936136 |               0.881673 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             7 |               0.952397 |               0.835628 |               0.900473 |               0.834499 |               0.909626 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             8 |               0.960484 |               0.897444 |               0.887378 |               0.919668 |               0.911336 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             9 |               0.942296 |               0.866391 |               0.841295 |               0.897413 |               0.865321 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             0 |               0.953001 |               0.948331 |               0.956504 |               0.9612   |               0.956542 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             1 |               0.974238 |               0.910039 |               0.941725 |               0.914275 |               0.942173 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             2 |               0.946364 |               0.945295 |               0.945794 |               0.907723 |               0.932102 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             3 |               0.937226 |               0.923594 |               0.887104 |               0.943861 |               0.90121  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             4 |               0.951494 |               0.915749 |               0.89884  |               0.945816 |               0.923446 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             5 |               0.985511 |               0.975287 |               0.965464 |               0.974018 |               0.969724 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             6 |               0.992804 |               0.980058 |               0.972198 |               0.980272 |               0.9693   |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             7 |               0.992001 |               0.963937 |               0.975197 |               0.965376 |               0.976698 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             8 |               0.99263  |               0.981941 |               0.979814 |               0.982305 |               0.979935 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             9 |               0.988543 |               0.966962 |               0.961971 |               0.963252 |               0.968425 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             0 |               0.93436  |               0.943828 |               0.947741 |               0.931188 |               0.93501  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             1 |               0.864501 |               0.841629 |               0.919528 |               0.902005 |               0.884426 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             2 |               0.912467 |               0.872885 |               0.90974  |               0.890759 |               0.921356 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             3 |               0.892928 |               0.879652 |               0.873895 |               0.905545 |               0.877263 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             4 |               0.951312 |               0.886128 |               0.86694  |               0.894645 |               0.863666 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             5 |               0.970534 |               0.947916 |               0.851898 |               0.969907 |               0.919695 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             6 |               0.985912 |               0.983999 |               0.965933 |               0.9759   |               0.968064 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             7 |               0.992137 |               0.945174 |               0.960632 |               0.941439 |               0.959904 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             8 |               0.992151 |               0.975521 |               0.97696  |               0.978838 |               0.980708 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             9 |               0.979186 |               0.950326 |               0.956795 |               0.948357 |               0.960316 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "no_questions = 10\n",
    "\n",
    "head = [\"Model\", \"Question no\", \"Similarity c1 and c2\", \"Similarity c1 and w1\",\"Similarity c1 and w2\", \"Similarity c2 and w1\", \"Similarity c2 and w2\"]\n",
    "print(\"cosine similarity\",\"question1\")\n",
    "print(tabulate(cosine__similarity_1, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKcAjWxhlMju",
    "outputId": "c6a79634-a777-4e85-f321-c6f1a6065244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity question2\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| Model                           |   Question no |   Similarity c1 and c2 |   Similarity c1 and w1 |   Similarity c1 and w2 |   Similarity c2 and w1 |   Similarity c2 and w2 |\n",
      "+=================================+===============+========================+========================+========================+========================+========================+\n",
      "| word2vec-google-news-300        |             0 |               0.948903 |               0.869924 |               0.753103 |               0.88375  |               0.778938 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             1 |               0.941341 |               0.886644 |               0.759519 |               0.872338 |               0.742464 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             2 |               0.944067 |               0.903608 |               0.911273 |               0.873595 |               0.887956 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             3 |               0.947099 |               0.853369 |               0.909426 |               0.86753  |               0.890907 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             4 |               0.951689 |               0.911961 |               0.839955 |               0.910304 |               0.851287 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             5 |               0.950888 |               0.912269 |               0.850597 |               0.876967 |               0.815566 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             6 |               0.959512 |               0.871851 |               0.891638 |               0.889925 |               0.901341 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             7 |               0.959274 |               0.894916 |               0.821892 |               0.895549 |               0.839057 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             8 |               0.934965 |               0.820227 |               0.838237 |               0.812251 |               0.800796 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             9 |               0.955406 |               0.801533 |               0.906808 |               0.788402 |               0.895088 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             0 |               0.98815  |               0.971742 |               0.914328 |               0.980233 |               0.922035 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             1 |               0.985671 |               0.972616 |               0.941267 |               0.966518 |               0.939773 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             2 |               0.985435 |               0.958863 |               0.978951 |               0.948757 |               0.970715 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             3 |               0.982112 |               0.95888  |               0.982553 |               0.96723  |               0.970468 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             4 |               0.991144 |               0.979639 |               0.937672 |               0.97619  |               0.935973 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             5 |               0.987225 |               0.983787 |               0.963812 |               0.97519  |               0.9482   |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             6 |               0.989838 |               0.973217 |               0.973375 |               0.975646 |               0.97874  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             7 |               0.98947  |               0.971735 |               0.951451 |               0.972933 |               0.95802  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             8 |               0.98497  |               0.942058 |               0.950958 |               0.942261 |               0.940483 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             9 |               0.991296 |               0.942707 |               0.970447 |               0.93672  |               0.970364 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             0 |               0.985763 |               0.97357  |               0.886687 |               0.976744 |               0.885815 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             1 |               0.981828 |               0.963866 |               0.891616 |               0.952884 |               0.89567  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             2 |               0.98287  |               0.949577 |               0.963127 |               0.942722 |               0.956887 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             3 |               0.9781   |               0.947067 |               0.965321 |               0.945954 |               0.94843  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             4 |               0.980835 |               0.960691 |               0.937323 |               0.968869 |               0.937014 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             5 |               0.970572 |               0.973119 |               0.947881 |               0.936769 |               0.916297 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             6 |               0.971265 |               0.945158 |               0.919851 |               0.960908 |               0.95771  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             7 |               0.987553 |               0.962133 |               0.929865 |               0.958219 |               0.939775 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             8 |               0.982492 |               0.939758 |               0.933624 |               0.946516 |               0.933201 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             9 |               0.981205 |               0.871777 |               0.907182 |               0.898121 |               0.940951 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "# from tabulate import tabulate\n",
    "\n",
    "no_questions = 10\n",
    "\n",
    "head = [\"Model\", \"Question no\", \"Similarity c1 and c2\", \"Similarity c1 and w1\",\"Similarity c1 and w2\", \"Similarity c2 and w1\", \"Similarity c2 and w2\"]\n",
    "print(\"cosine similarity\",\"question2\")\n",
    "\n",
    "print(tabulate(cosine__similarity_2, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0yYvK21rSUF",
    "outputId": "5219f9f7-00e0-4ce7-851c-b4203a7ef952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmddistance similarity question1\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| Model                           |   Question no |   Similarity c1 and c2 |   Similarity c1 and w1 |   Similarity c1 and w2 |   Similarity c2 and w1 |   Similarity c2 and w2 |\n",
      "+=================================+===============+========================+========================+========================+========================+========================+\n",
      "| word2vec-google-news-300        |             0 |               0.511557 |               0.502985 |               0.504611 |               0.558805 |               0.531213 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             1 |               0.621384 |               0.485605 |               0.503752 |               0.479688 |               0.512069 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             2 |               0.565691 |               0.517178 |               0.499205 |               0.492829 |               0.470929 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             3 |               0.541009 |               0.485488 |               0.49993  |               0.473553 |               0.482161 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             4 |               0.566667 |               0.487918 |               0.508063 |               0.532864 |               0.505251 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             5 |               0.645088 |               0.548651 |               0.534378 |               0.528315 |               0.527961 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             6 |               0.608257 |               0.564552 |               0.540995 |               0.545233 |               0.546399 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             7 |               0.603321 |               0.533648 |               0.54103  |               0.52233  |               0.54285  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             8 |               0.645761 |               0.556212 |               0.537957 |               0.5705   |               0.55906  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             9 |               0.626358 |               0.554008 |               0.546515 |               0.556185 |               0.535239 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             0 |               0.585178 |               0.58357  |               0.590605 |               0.619024 |               0.603688 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             1 |               0.665286 |               0.559953 |               0.572758 |               0.56828  |               0.585096 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             2 |               0.615979 |               0.582743 |               0.573506 |               0.569805 |               0.563633 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             3 |               0.59622  |               0.556434 |               0.563179 |               0.550415 |               0.556226 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             4 |               0.645132 |               0.557659 |               0.567431 |               0.604806 |               0.562378 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             5 |               0.710064 |               0.624958 |               0.607554 |               0.616456 |               0.611702 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             6 |               0.681067 |               0.636758 |               0.613471 |               0.627764 |               0.626227 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             7 |               0.68932  |               0.618849 |               0.624857 |               0.607319 |               0.625113 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             8 |               0.728398 |               0.633038 |               0.629263 |               0.646847 |               0.648435 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             9 |               0.701818 |               0.631187 |               0.628034 |               0.628502 |               0.62019  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             0 |               0.572418 |               0.577122 |               0.582193 |               0.613372 |               0.5946   |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             1 |               0.637069 |               0.545759 |               0.567263 |               0.560694 |               0.573977 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             2 |               0.612394 |               0.569168 |               0.565419 |               0.567202 |               0.560487 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             3 |               0.579394 |               0.550917 |               0.557528 |               0.54974  |               0.557041 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             4 |               0.648577 |               0.551919 |               0.561535 |               0.598834 |               0.553866 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             5 |               0.705811 |               0.610153 |               0.581496 |               0.610323 |               0.59532  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             6 |               0.676765 |               0.642568 |               0.613056 |               0.623505 |               0.624329 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             7 |               0.692134 |               0.611909 |               0.614318 |               0.597451 |               0.614554 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             8 |               0.72285  |               0.634418 |               0.626137 |               0.647576 |               0.647065 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             9 |               0.694234 |               0.62282  |               0.622687 |               0.617507 |               0.614305 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "head = [\"Model\", \"Question no\", \"Similarity c1 and c2\", \"Similarity c1 and w1\",\"Similarity c1 and w2\", \"Similarity c2 and w1\", \"Similarity c2 and w2\"]\n",
    "print(\"wmddistance similarity\",\"question1\")\n",
    "print(tabulate(wmd_distance_similarity_1, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3OfPVTMlops",
    "outputId": "959c7e5f-a1a2-428b-d67d-564e74957599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmddistance similarity question2\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| Model                           |   Question no |   Similarity c1 and c2 |   Similarity c1 and w1 |   Similarity c1 and w2 |   Similarity c2 and w1 |   Similarity c2 and w2 |\n",
      "+=================================+===============+========================+========================+========================+========================+========================+\n",
      "| word2vec-google-news-300        |             0 |               0.586753 |               0.521007 |               0.479094 |               0.535759 |               0.476907 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             1 |               0.57108  |               0.528486 |               0.463858 |               0.528031 |               0.465504 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             2 |               0.582278 |               0.526299 |               0.531355 |               0.491131 |               0.503682 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             3 |               0.603918 |               0.52926  |               0.563331 |               0.538198 |               0.550165 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             4 |               0.59658  |               0.568458 |               0.513565 |               0.549247 |               0.500015 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             5 |               0.625028 |               0.56551  |               0.54146  |               0.544364 |               0.522016 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             6 |               0.625561 |               0.535204 |               0.532899 |               0.539991 |               0.538971 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             7 |               0.636047 |               0.552796 |               0.508098 |               0.553115 |               0.519483 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             8 |               0.588441 |               0.490444 |               0.502038 |               0.485487 |               0.498937 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             9 |               0.62798  |               0.504426 |               0.548322 |               0.497398 |               0.534074 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             0 |               0.673481 |               0.615776 |               0.553962 |               0.63888  |               0.556366 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             1 |               0.658009 |               0.615667 |               0.551609 |               0.618731 |               0.546288 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             2 |               0.666273 |               0.601055 |               0.622075 |               0.573119 |               0.594065 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             3 |               0.668125 |               0.59825  |               0.648401 |               0.608458 |               0.622029 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             4 |               0.682396 |               0.654735 |               0.594278 |               0.64553  |               0.583459 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             5 |               0.703149 |               0.644472 |               0.6187   |               0.626462 |               0.596694 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             6 |               0.694562 |               0.622249 |               0.613423 |               0.628855 |               0.625633 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             7 |               0.711745 |               0.635492 |               0.575165 |               0.642752 |               0.588706 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             8 |               0.662584 |               0.571662 |               0.576495 |               0.573257 |               0.576314 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             9 |               0.702169 |               0.56169  |               0.612958 |               0.556378 |               0.600109 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             0 |               0.671804 |               0.613646 |               0.548277 |               0.630623 |               0.548016 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             1 |               0.655652 |               0.612831 |               0.536359 |               0.609718 |               0.536333 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             2 |               0.661753 |               0.594793 |               0.610865 |               0.567597 |               0.581402 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             3 |               0.665046 |               0.596221 |               0.632021 |               0.608953 |               0.612167 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             4 |               0.674282 |               0.63766  |               0.589763 |               0.639422 |               0.578126 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             5 |               0.693523 |               0.640545 |               0.615248 |               0.615024 |               0.593698 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             6 |               0.682281 |               0.609683 |               0.593567 |               0.615369 |               0.608828 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             7 |               0.702428 |               0.624476 |               0.56017  |               0.626017 |               0.575488 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             8 |               0.66487  |               0.568521 |               0.570177 |               0.567476 |               0.569905 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             9 |               0.700981 |               0.560011 |               0.601954 |               0.559736 |               0.594765 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "head = [\"Model\", \"Question no\", \"Similarity c1 and c2\", \"Similarity c1 and w1\",\"Similarity c1 and w2\", \"Similarity c2 and w1\", \"Similarity c2 and w2\"]\n",
    "print(\"wmddistance similarity\",\"question2\")\n",
    "print(tabulate(wmd_distance_similarity_2, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7t9pIbRrWgU",
    "outputId": "1d2adf11-fa42-44d8-cba7-1528072c64ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " soft cosine similarity question1\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| Model                           |   Question no |   Similarity c1 and c2 |   Similarity c1 and w1 |   Similarity c1 and w2 |   Similarity c2 and w1 |   Similarity c2 and w2 |\n",
      "+=================================+===============+========================+========================+========================+========================+========================+\n",
      "| word2vec-google-news-300        |             0 |               0.454779 |               0.512415 |               0.479445 |               0.518532 |               0.437073 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             1 |               0.476789 |               0.451218 |               0.452537 |               0.501514 |               0.380043 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             2 |               0.562628 |               0.435935 |               0.402598 |               0.427312 |               0.436175 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             3 |               0.432685 |               0.346113 |               0.413082 |               0.317427 |               0.383248 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             4 |               0.595149 |               0.235107 |               0.353553 |               0.374241 |               0.361643 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             5 |               0.847979 |               0.641947 |               0.546838 |               0.632412 |               0.575403 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             6 |               0.780909 |               0.690735 |               0.688313 |               0.667071 |               0.714752 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             7 |               0.845088 |               0.606832 |               0.688145 |               0.578608 |               0.675481 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             8 |               0.839911 |               0.718495 |               0.714077 |               0.75581  |               0.7678   |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             9 |               0.818001 |               0.611021 |               0.600239 |               0.62646  |               0.619346 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             0 |               0.736642 |               0.706187 |               0.732375 |               0.787485 |               0.72485  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             1 |               0.798219 |               0.601519 |               0.654767 |               0.66076  |               0.690316 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             2 |               0.793005 |               0.758472 |               0.734962 |               0.67988  |               0.611464 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             3 |               0.722303 |               0.528549 |               0.55672  |               0.682681 |               0.698553 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             4 |               0.72305  |               0.446238 |               0.475943 |               0.635573 |               0.571203 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             5 |               0.928119 |               0.857544 |               0.818174 |               0.845187 |               0.82953  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             6 |               0.925581 |               0.882292 |               0.805736 |               0.881464 |               0.823873 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             7 |               0.930454 |               0.835539 |               0.855554 |               0.822682 |               0.853013 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             8 |               0.93051  |               0.858097 |               0.868917 |               0.860238 |               0.878564 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             9 |               0.92497  |               0.780206 |               0.823093 |               0.797329 |               0.864015 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             0 |               0.560601 |               0.579991 |               0.55958  |               0.623528 |               0.533051 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             1 |               0.676953 |               0.506255 |               0.502534 |               0.638059 |               0.610826 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             2 |               0.725753 |               0.521175 |               0.606032 |               0.505225 |               0.536622 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             3 |               0.488369 |               0.38672  |               0.40373  |               0.445849 |               0.435582 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             4 |               0.670516 |               0.387198 |               0.380731 |               0.501832 |               0.396391 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             5 |               0.88437  |               0.734758 |               0.661483 |               0.68969  |               0.664839 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             6 |               0.852986 |               0.774291 |               0.738802 |               0.738138 |               0.75778  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             7 |               0.887648 |               0.687884 |               0.752506 |               0.661909 |               0.757939 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             8 |               0.88779  |               0.791956 |               0.806149 |               0.818138 |               0.847631 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             9 |               0.887228 |               0.701596 |               0.681373 |               0.708496 |               0.699843 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "head = [\"Model\", \"Question no\", \"Similarity c1 and c2\", \"Similarity c1 and w1\",\"Similarity c1 and w2\", \"Similarity c2 and w1\", \"Similarity c2 and w2\"]\n",
    "print(\" soft cosine similarity\",\"question1\")\n",
    "print(tabulate(soft_cosine_1, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CXE14q4lwKd",
    "outputId": "3b389773-8e98-4935-81a3-7990dc511e6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " soft cosine similarity question2\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| Model                           |   Question no |   Similarity c1 and c2 |   Similarity c1 and w1 |   Similarity c1 and w2 |   Similarity c2 and w1 |   Similarity c2 and w2 |\n",
      "+=================================+===============+========================+========================+========================+========================+========================+\n",
      "| word2vec-google-news-300        |             0 |               0.779867 |               0.675367 |               0.410837 |               0.739517 |               0.415032 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             1 |               0.80298  |               0.724642 |               0.321495 |               0.73161  |               0.308737 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             2 |               0.757223 |               0.640331 |               0.671985 |               0.496184 |               0.580691 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             3 |               0.749557 |               0.502154 |               0.670933 |               0.526369 |               0.621791 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             4 |               0.776945 |               0.649503 |               0.545407 |               0.619022 |               0.506051 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             5 |               0.820136 |               0.69425  |               0.597367 |               0.613328 |               0.498912 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             6 |               0.77731  |               0.563914 |               0.560888 |               0.63522  |               0.615819 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             7 |               0.802891 |               0.665382 |               0.410323 |               0.717412 |               0.473449 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             8 |               0.758339 |               0.501251 |               0.484797 |               0.486166 |               0.436981 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| word2vec-google-news-300        |             9 |               0.855819 |               0.381035 |               0.56783  |               0.384581 |               0.556576 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             0 |               0.903997 |               0.814239 |               0.66221  |               0.871909 |               0.674921 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             1 |               0.898914 |               0.819079 |               0.729723 |               0.838168 |               0.708215 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             2 |               0.896793 |               0.782532 |               0.849723 |               0.751805 |               0.833601 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             3 |               0.896748 |               0.73953  |               0.853494 |               0.750472 |               0.795855 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             4 |               0.921164 |               0.872356 |               0.724088 |               0.866022 |               0.721333 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             5 |               0.896263 |               0.827922 |               0.767581 |               0.765165 |               0.730312 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             6 |               0.914773 |               0.802825 |               0.81807  |               0.824712 |               0.851617 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             7 |               0.913059 |               0.836505 |               0.67652  |               0.853556 |               0.71392  |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             8 |               0.866695 |               0.69911  |               0.716289 |               0.672589 |               0.639497 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| glove-wiki-gigaword-100         |             9 |               0.908783 |               0.658194 |               0.759781 |               0.59608  |               0.712107 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             0 |               0.847318 |               0.769895 |               0.487877 |               0.809802 |               0.498064 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             1 |               0.854083 |               0.772962 |               0.533905 |               0.791922 |               0.498304 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             2 |               0.836745 |               0.713104 |               0.746043 |               0.618617 |               0.680794 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             3 |               0.799558 |               0.585276 |               0.762532 |               0.600466 |               0.698555 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             4 |               0.857486 |               0.743541 |               0.633254 |               0.763721 |               0.625261 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             5 |               0.858301 |               0.741703 |               0.689442 |               0.671378 |               0.620668 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             6 |               0.843833 |               0.701995 |               0.664869 |               0.755298 |               0.706233 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             7 |               0.871084 |               0.759317 |               0.512625 |               0.772295 |               0.516474 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             8 |               0.808545 |               0.584991 |               0.547926 |               0.559188 |               0.518444 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "| fasttext-wiki-news-subwords-300 |             9 |               0.913485 |               0.576489 |               0.690437 |               0.59851  |               0.701909 |\n",
      "+---------------------------------+---------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "head = [\"Model\", \"Question no\", \"Similarity c1 and c2\", \"Similarity c1 and w1\",\"Similarity c1 and w2\", \"Similarity c2 and w1\", \"Similarity c2 and w2\"]\n",
    "print(\" soft cosine similarity\",\"question2\")\n",
    "print(tabulate(soft_cosine_2, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Phu6rOjTkkoi",
    "outputId": "931f16ed-0fd6-4932-ebbb-9cf7faf96a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question1, cosine similarity\n",
      "+---------------------------------+----------+\n",
      "| model                           |    value |\n",
      "+=================================+==========+\n",
      "| word2vec-google-news-300        | 0.895869 |\n",
      "+---------------------------------+----------+\n",
      "| glove-wiki-gigaword-100         | 0.200448 |\n",
      "+---------------------------------+----------+\n",
      "| fasttext-wiki-news-subwords-300 | 0.208961 |\n",
      "+---------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "value = 0\n",
    "final_value_1 = []\n",
    "j=0\n",
    "\n",
    "for i in range(len(cosine__similarity_1)):\n",
    "  if i%no_questions == 0 and i!=0:\n",
    "    final_value_1.append([model[j],value])\n",
    "    value = 0\n",
    "    j=j+1\n",
    "\n",
    "  value = value + cosine__similarity_1[i][2]-(cosine__similarity_1[i][3] + cosine__similarity_1[i][4] + cosine__similarity_1[i][5] + cosine__similarity_1[i][6])/4\n",
    "\n",
    "final_value_1.append([model[j],value])\n",
    "head = [\"model\", \"value\"]\n",
    "print(\"question1,\",\"cosine similarity\")\n",
    "print(tabulate(final_value_1, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FaYitGssmFD9",
    "outputId": "47d96895-d6d9-4862-823b-149ff2ab5853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question2,cosine similarity\n",
      "+---------------------------------+----------+\n",
      "| model                           |    value |\n",
      "+=================================+==========+\n",
      "| word2vec-google-news-300        | 0.922454 |\n",
      "+---------------------------------+----------+\n",
      "| glove-wiki-gigaword-100         | 0.276184 |\n",
      "+---------------------------------+----------+\n",
      "| fasttext-wiki-news-subwords-300 | 0.410321 |\n",
      "+---------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "value = 0\n",
    "final_value_2 = []\n",
    "j=0\n",
    "\n",
    "for i in range(len(cosine__similarity_2)):\n",
    "  if i%no_questions == 0 and i!=0:\n",
    "    final_value_2.append([model[j],value])\n",
    "    value = 0\n",
    "    j=j+1\n",
    "\n",
    "  value = value + cosine__similarity_2[i][2]-(cosine__similarity_2[i][3] + cosine__similarity_2[i][4] + cosine__similarity_2[i][5] + cosine__similarity_2[i][6])/4\n",
    "\n",
    "final_value_2.append([model[j],value])\n",
    "head = [\"model\", \"value\"]\n",
    "print(\"question2,\" \"cosine similarity\")\n",
    "print(tabulate(final_value_2, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFrG78pjsNe2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sB2Qjnokkyt",
    "outputId": "e42faa4a-229c-4178-d865-bb52a55f3d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question1, wmd distance similarity\n",
      "+---------------------------------+----------+\n",
      "| model                           |    value |\n",
      "+=================================+==========+\n",
      "| word2vec-google-news-300        | 0.703564 |\n",
      "+---------------------------------+----------+\n",
      "| glove-wiki-gigaword-100         | 0.619033 |\n",
      "+---------------------------------+----------+\n",
      "| fasttext-wiki-news-subwords-300 | 0.609113 |\n",
      "+---------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "value = 0\n",
    "final_value_1 = []\n",
    "j=0\n",
    "\n",
    "for i in range(len(wmd_distance_similarity_1)):\n",
    "  if i%no_questions == 0 and i!=0:\n",
    "    final_value_1.append([model[j],value])\n",
    "    value = 0\n",
    "    j=j+1\n",
    "\n",
    "  value = value + wmd_distance_similarity_1[i][2]-(wmd_distance_similarity_1[i][3] + wmd_distance_similarity_1[i][4] + wmd_distance_similarity_1[i][5] + wmd_distance_similarity_1[i][6])/4\n",
    "\n",
    "final_value_1.append([model[j],value])\n",
    "head = [\"model\", \"value\"]\n",
    "print(\"question1,\",\"wmd distance similarity\")\n",
    "print(tabulate(final_value_1, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRIv9EdumoJf",
    "outputId": "86c3c780-ac5b-4095-f06b-06040d26f6c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question2, wmd distance similarity\n",
      "+---------------------------------+----------+\n",
      "| model                           |    value |\n",
      "+=================================+==========+\n",
      "| word2vec-google-news-300        | 0.82407  |\n",
      "+---------------------------------+----------+\n",
      "| glove-wiki-gigaword-100         | 0.799942 |\n",
      "+---------------------------------+----------+\n",
      "| fasttext-wiki-news-subwords-300 | 0.833757 |\n",
      "+---------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "value = 0\n",
    "final_value_2 = []\n",
    "j=0\n",
    "\n",
    "for i in range(len(wmd_distance_similarity_2)):\n",
    "  if i%no_questions == 0 and i!=0:\n",
    "    final_value_2.append([model[j],value])\n",
    "    value = 0\n",
    "    j=j+1\n",
    "\n",
    "  value = value + wmd_distance_similarity_2[i][2]-(wmd_distance_similarity_2[i][3] + wmd_distance_similarity_2[i][4] + wmd_distance_similarity_2[i][5] + wmd_distance_similarity_2[i][6])/4\n",
    "\n",
    "final_value_2.append([model[j],value])\n",
    "head = [\"model\", \"value\"]\n",
    "print(\"question2,\",\"wmd distance similarity\")\n",
    "print(tabulate(final_value_2, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8v48wiYNsOsW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWJL4qepkk7D",
    "outputId": "792cb959-9b1f-4a11-a391-768fea0966cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question1, soft cosine\n",
      "+---------------------------------+----------+\n",
      "| model                           |    value |\n",
      "+=================================+==========+\n",
      "| word2vec-google-news-300        | 1.31917  |\n",
      "+---------------------------------+----------+\n",
      "| glove-wiki-gigaword-100         | 0.967965 |\n",
      "+---------------------------------+----------+\n",
      "| fasttext-wiki-news-subwords-300 | 1.33819  |\n",
      "+---------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "value = 0\n",
    "final_value_1 = []\n",
    "j=0\n",
    "\n",
    "for i in range(len(soft_cosine_1)):\n",
    "  if i%no_questions == 0 and i!=0:\n",
    "    final_value_1.append([model[j],value])\n",
    "    value = 0\n",
    "    j=j+1\n",
    "\n",
    "  value = value + soft_cosine_1[i][2]-(soft_cosine_1[i][3] + soft_cosine_1[i][4] + soft_cosine_1[i][5] + soft_cosine_1[i][6])/4\n",
    "\n",
    "final_value_1.append([model[j],value])\n",
    "head = [\"model\", \"value\"]\n",
    "print(\"question1,\",\"soft cosine\")\n",
    "print(tabulate(final_value_1, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zt8iNWJSUYZl",
    "outputId": "7e3b4dd3-fc57-4d14-d3c6-23c2511e1d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question2, soft cosine\n",
      "+---------------------------------+---------+\n",
      "| model                           |   value |\n",
      "+=================================+=========+\n",
      "| word2vec-google-news-300        | 2.33028 |\n",
      "+---------------------------------+---------+\n",
      "| glove-wiki-gigaword-100         | 1.37178 |\n",
      "+---------------------------------+---------+\n",
      "| fasttext-wiki-news-subwords-300 | 1.93442 |\n",
      "+---------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "value = 0\n",
    "final_value_2 = []\n",
    "j=0\n",
    "\n",
    "for i in range(len(soft_cosine_2)):\n",
    "  if i%no_questions == 0 and i!=0:\n",
    "    final_value_2.append([model[j],value])\n",
    "    value = 0\n",
    "    j=j+1\n",
    "\n",
    "  value = value + soft_cosine_2[i][2]-(soft_cosine_2[i][3] + soft_cosine_2[i][4] + soft_cosine_2[i][5] + soft_cosine_2[i][6])/4\n",
    "\n",
    "final_value_2.append([model[j],value])\n",
    "print(\"question2,\",\"soft cosine\")\n",
    "print(tabulate(final_value_2, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgA4yegOpzxy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
